{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgiYwgnKmM8c",
    "outputId": "f80c1d0e-ca3d-47d3-c8e0-8435ff51f484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting koalas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/72/4048c6965c4c923bd88e82d0748eeed5bc02c74cf36d88645d974367e3b3/koalas-1.8.1-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 7.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from koalas) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->koalas) (1.15.0)\n",
      "Installing collected packages: koalas\n",
      "Successfully installed koalas-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koalas \n",
    "The Koalas project makes data scientists more productive when interacting with big data, by implementing the pandas DataFrame API on top of Apache Spark. pandas is the de facto standard (single-node) DataFrame implementation in Python, while Spark is the de facto standard for big data processing. With this package, you can:\n",
    "\n",
    "Be immediately productive with Spark, with no learning curve, if you are already familiar with pandas.\n",
    "\n",
    "Have a single codebase that works both with pandas (tests, smaller datasets) and with Spark (distributed datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcJjeorFmO3D",
    "outputId": "87e1e58c-6b21-453f-d28d-80860638cab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow==0.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/ee/fd2d696eff911f76ed14feeb51e6db6783dd04abd9b8e14be4cbf48d6088/pyarrow-0.15.1-cp37-cp37m-manylinux2010_x86_64.whl (59.2MB)\n",
      "\u001b[K     |████████████████████████████████| 59.2MB 51kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from pyarrow==0.15.1) (1.19.5)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pyarrow==0.15.1) (1.15.0)\n",
      "Installing collected packages: pyarrow\n",
      "  Found existing installation: pyarrow 3.0.0\n",
      "    Uninstalling pyarrow-3.0.0:\n",
      "      Successfully uninstalled pyarrow-3.0.0\n",
      "Successfully installed pyarrow-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==0.15.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyArrow\n",
    "PyArrow includes Python bindings to this code, which thus enables reading and writing Parquet files with pandas as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwIjqZ43mQiP"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null  #\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.0.3-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java.\n",
    " \n",
    "2. we will install Apache Spark 3.0.3 with Hadoop 3.2 and we ll unzip it\n",
    " \n",
    "3. There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0PT_cjomTAY",
    "outputId": "0aa9145a-7619-4d98-d378-39d796c318ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
      "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/lib/jvm/ # Checking java path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gv-3SvqNmVEQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have installed all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run Pyspark in the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGIyTtBnmXR_"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPmdjZOqmZLG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgMQapGwma3X"
   },
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    "df_koalas=ks.read_csv(\"/content/census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "YdrYrGa6mm5n",
    "outputId": "995415f7-da3c-4c7d-b19d-fc6686021dc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>greater_than_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass    education  education_num       marital_status          occupation relationship    race   gender  hours_per_week  native_country  greater_than_50k\n",
       "32555   27        Private   Assoc-acdm             12   Married-civ-spouse        Tech-support         Wife   White   Female              38   United-States                 0\n",
       "32556   40        Private      HS-grad              9   Married-civ-spouse   Machine-op-inspct      Husband   White     Male              40   United-States                 1\n",
       "32557   58        Private      HS-grad              9              Widowed        Adm-clerical    Unmarried   White   Female              40   United-States                 0\n",
       "32558   22        Private      HS-grad              9        Never-married        Adm-clerical    Own-child   White     Male              20   United-States                 0\n",
       "32559   52   Self-emp-inc      HS-grad              9   Married-civ-spouse     Exec-managerial         Wife   White   Female              40   United-States                 1"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_koalas.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "al9h26gUmsZn",
    "outputId": "b55064eb-dd7f-4dc2-ea1d-8d1025e3755a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32560, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_koalas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ker6wj5cUMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spark 3 on google colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
